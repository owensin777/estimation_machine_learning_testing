{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565f6b65-619b-488f-b0c3-afbc31cfbff1",
   "metadata": {},
   "source": [
    "# 6.10: Unsupervised Learning Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864ed9f-ef24-462e-a7a2-01fa1438a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and objects\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.datasets import get_rdataset\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data\n",
    "from sklearn.cluster import \\\n",
    "     (KMeans,\n",
    "      AgglomerativeClustering)\n",
    "from scipy.cluster.hierarchy import \\\n",
    "     (dendrogram,\n",
    "      cut_tree)\n",
    "from ISLP.cluster import compute_linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004489c9-0fcf-4361-a69a-bc7bc0570946",
   "metadata": {},
   "source": [
    "### Principal Components Analysis\n",
    "In this lab, we perform PCA on `USArrests`. This is a standard R package which get in Python using `get_rdataset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca756bc-a5f5-44d8-97f3-a9fb3d81e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "USArrests = get_rdataset('USArrests').data\n",
    "USArrests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250535f-437a-4468-831b-f5ec42a3cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at our data\n",
    "USArrests.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2b40b-d2fb-4741-84cf-37fa3fed4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "USArrests.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946213c-aefb-49c2-8c7c-fd402f56e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the variance of the four variables using the var() method\n",
    "USArrests.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ad9d7-c8ae-4498-8554-80bc279fba48",
   "metadata": {},
   "source": [
    "If the variables are measured in different units or vary widely in scale, it is recommended to standardize the variables to have standard deviation one before performing PCA. We can do this via the `StandardScaler()` transform imported above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fdf19e-f4b1-41ee-8873-a499d555d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_std=True,\n",
    "                        with_mean=True)\n",
    "USArrests_scaled = scaler.fit_transform(USArrests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa4969-2106-44b2-9ecf-51e3e4b8e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform principal components analysis\n",
    "pcaUS = PCA()\n",
    "\n",
    "# Fit\n",
    "pcaUS.fit(USArrests_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2558d22-2bc8-4471-947a-87b33f1e4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check means of the variables\n",
    "pcaUS.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c6d69b-5fb5-48c4-971b-a019b09f2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute scores\n",
    "scores = pcaUS.transform(USArrests_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f438a8-df18-44a6-a4d4-504cdfd1bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = 0, 1 # which components\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.scatter(scores[:,0], scores[:,1])\n",
    "ax.set_xlabel('PC%d' % (i+1))\n",
    "ax.set_ylabel('PC%d' % (j+1))\n",
    "for k in range(pcaUS.components_.shape[1]):\n",
    "    ax.arrow(0, 0, pcaUS.components_[i,k], pcaUS.components_[j,k])\n",
    "    ax.text(pcaUS.components_[i,k],\n",
    "            pcaUS.components_[j,k],\n",
    "            USArrests.columns[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8856804-971d-4767-aead-8d5afdfc9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_arrow = s_ = 2\n",
    "scores[:,1] *= -1\n",
    "pcaUS.components_[1] *= -1 # flip the y-axis\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.scatter(scores[:,0], scores[:,1])\n",
    "ax.set_xlabel('PC%d' % (i+1))\n",
    "ax.set_ylabel('PC%d' % (j+1))\n",
    "for k in range(pcaUS.components_.shape[1]):\n",
    "    ax.arrow(0, 0, s_*pcaUS.components_[i,k], s_*pcaUS.components_[j,k])\n",
    "    ax.text(s_*pcaUS.components_[i,k],\n",
    "            s_*pcaUS.components_[j,k],\n",
    "            USArrests.columns[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ffdbe-a0d1-46da-a228-0d6f88997270",
   "metadata": {},
   "source": [
    "Let's take a look at the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b318d32-1956-4a91-8173-b997e7b34641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation\n",
    "scores.std(0, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80fb32-dba4-48e4-aeca-b606423bb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance of each score\n",
    "pcaUS.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f22bc3-79d4-40b8-bcb4-f6f470da7c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proportion of variance explained by each principal component (PVE) \n",
    "pcaUS.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f796b71-068f-4b05-bc97-dcd3e0b5363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the proportion of variance explained\n",
    "ticks = np.arange(1, len(pcaUS.explained_variance_ratio_) + 1)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "ax.plot(ticks,\n",
    "        pcaUS.explained_variance_ratio_.cumsum(),\n",
    "        marker='o')\n",
    "ax.set_xlabel('Principal Component')\n",
    "ax.set_ylabel('Cumulative Proportion of Variance Explained')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_xticks(ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051eba01-d276-47b6-8243-ee3ca7172fc0",
   "metadata": {},
   "source": [
    "### Matrix Completion\n",
    "\n",
    "We will turn our `USArrests` data into a matrix.\n",
    "\n",
    "We now omit 20 entries in the $50$ x $4$ data matrix at random. We do so by first selecting 20 rows (states) at random, and then selecting one of the four entries in each row at random. This ensures that every row has at least three observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35b0f7-fe07-43fa-b31b-59dc17c3fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_omit = 20\n",
    "np.random.seed(15)\n",
    "X = USArrests.values\n",
    "r_idx = np.random.choice(np.arange(X.shape[0]),\n",
    "                         n_omit,\n",
    "                         replace=False)\n",
    "c_idx = np.random.choice(np.arange(X.shape[1]),\n",
    "                         n_omit,\n",
    "                         replace=True)\n",
    "Xna = X.copy()\n",
    "Xna[r_idx, c_idx] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889f0c5-1a23-4a15-8c00-8dc6809213d0",
   "metadata": {},
   "source": [
    "To start, we replace the missing values with the column means of the non-missing entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3401f09-9b05-4d3f-a13d-3eba3a636c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Xna to NumPy array\n",
    "\n",
    "Xhat = Xna.copy()\n",
    "Xbar = np.nanmean(Xhat, axis=0)\n",
    "Xhat[r_idx, c_idx] = Xbar[c_idx]\n",
    "\n",
    "def low_rank(X, M=1):\n",
    "    U, D, V = np.linalg.svd(X)\n",
    "    L = U[:,:M] * D[None,:M]\n",
    "    return L.dot(V[:M])\n",
    "\n",
    "# Measure progress\n",
    "thresh = 1e-7\n",
    "rel_err = 1\n",
    "count = 0\n",
    "ismiss = np.isnan(Xna)\n",
    "mssold = np.mean(Xhat[~ismiss]**2)\n",
    "mss0 = np.mean(Xna[~ismiss]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba01cb7-667e-42a2-ad10-95b1653440e2",
   "metadata": {},
   "source": [
    "In Step 2(a) of Algorithm 12.1, we  approximate `Xhat` using `low_rank()`; we call this `Xapp`. In Step 2(b), we  use `Xapp`  to update the estimates for elements in `Xhat` that are missing in `Xna`. Finally, in Step 2(c), we compute the relative error. These three steps are contained in the following `while` loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c509e70-d671-478c-b0d5-ec7c066abd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while rel_err > thresh:\n",
    "    count += 1\n",
    "    # Step 2(a)\n",
    "    Xapp = low_rank(Xhat, M=1)\n",
    "    # Step 2(b)\n",
    "    Xhat[ismiss] = Xapp[ismiss]\n",
    "    # Step 2(c)\n",
    "    mss = np.mean(((Xna - Xapp)[~ismiss])**2)\n",
    "    rel_err = (mssold - mss) / mss0\n",
    "    mssold = mss\n",
    "    print(\"Iteration: {0}, MSS:{1:.3f}, Rel.Err {2:.2e}\"\n",
    "          .format(count, mss, rel_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12696b-39e7-4501-a66e-fb478b5cfad4",
   "metadata": {},
   "source": [
    "### $K$-Means Clustering\n",
    "\n",
    "The estimator `sklearn.cluster.KMeans()`  performs $K$-means clustering in\n",
    "`Python`.  We begin with a simple simulated example in which there\n",
    "truly are two clusters in the data: the first 25 observations have a\n",
    "mean shift relative to the next 25 observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ad6d1-af81-45ab-a81b-a8278c85ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0);\n",
    "X = np.random.standard_normal((50,2));\n",
    "X[:25,0] += 3;\n",
    "X[:25,1] -= 4;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f085b-48a5-43e9-8d32-2cd38d7dcadf",
   "metadata": {},
   "source": [
    "We now perform $K$-means clustering with $K=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c9d42-b44c-476a-8932-f45a905ad0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2,\n",
    "                random_state=16, # for reproducibility\n",
    "                n_init=20).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c6ee9-03b8-4686-9ec3-2b47e9559b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cluster assignments\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ecbd2-83ae-40ef-9504-1327fc8f93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our findings\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "ax.scatter(X[:,0], X[:,1], c=kmeans.labels_)\n",
    "ax.set_title(\"K-Means Clustering Results with K=2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9ddee-d8db-4c2b-9232-ccac83055764",
   "metadata": {},
   "source": [
    "We knew there were 2 groups in this dataset but in real life we would not. So, let's see how K-means does with $K = 3$ clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d628ab2-7dc7-4641-888b-b37abfbcc6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3,\n",
    "                random_state=3,\n",
    "                n_init=20).fit(X)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.scatter(X[:,0], X[:,1], c=kmeans.labels_)\n",
    "ax.set_title(\"K-Means Clustering Results with K=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efcab97-660c-41b8-a66b-c165593441f3",
   "metadata": {},
   "source": [
    "When $K=3$, $K$-means clustering  splits up the two clusters.\n",
    "We have used the `n_init` argument to run the $K$-means with 20 \n",
    "initial cluster assignments (the default is 10). If a\n",
    "value of `n_init` greater than one is used, then $K$-means\n",
    "clustering will be performed using multiple random assignments in\n",
    "Step 1 and the `KMeans()` \n",
    "function will report only the best results. Here we compare using\n",
    "`n_init=1` to `n_init=20`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb19cdf5-cbf5-443e-80b5-b50d95e3f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans1 = KMeans(n_clusters=3,\n",
    "                random_state=3,\n",
    "                n_init=1).fit(X)\n",
    "kmeans20 = KMeans(n_clusters=3,\n",
    "                  random_state=3,\n",
    "                  n_init=20).fit(X);\n",
    "kmeans1.inertia_, kmeans20.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61af406-3a47-42a0-af77-ca986dddb967",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering\n",
    "\n",
    "The `AgglomerativeClustering()`  class from\n",
    "the `sklearn.clustering` package implements hierarchical clustering.\n",
    "As its\n",
    "name is long, we use the short hand `HClust` for *hierarchical clustering*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0130ec7e-57dc-44ed-83aa-a4975c1dbb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by clustering observations using complete linkage\n",
    "HClust = AgglomerativeClustering\n",
    "hc_comp = HClust(distance_threshold=0,\n",
    "                 n_clusters=None,\n",
    "                 linkage='complete')\n",
    "hc_comp.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99261d40-6269-41fd-9d95-aa4a9d39a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_avg = HClust(distance_threshold=0,\n",
    "                n_clusters=None,\n",
    "                linkage='average');\n",
    "hc_avg.fit(X)\n",
    "hc_sing = HClust(distance_threshold=0,\n",
    "                 n_clusters=None,\n",
    "                 linkage='single');\n",
    "hc_sing.fit(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198eb476-d524-436a-b1e1-2201bd6c85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the dendrograms\n",
    "cargs = {'color_threshold':-np.inf,\n",
    "         'above_threshold_color':'black'}\n",
    "linkage_comp = compute_linkage(hc_comp)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "dendrogram(linkage_comp,\n",
    "           ax=ax,\n",
    "           **cargs);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c863b-aa20-43fd-856d-2b1e8cafc879",
   "metadata": {},
   "source": [
    "To determine the cluster labels for each observation associated with a\n",
    "given cut of the dendrogram, we can use the `cut_tree()` \n",
    "function from `scipy.cluster.hierarchy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd6073d-456a-49d6-be74-265dd78e25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_tree(linkage_comp, n_clusters=4).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c43c1-1aa5-4f76-9271-e317e727077a",
   "metadata": {},
   "source": [
    "This can also be achieved by providing an argument `n_clusters`\n",
    "to `HClust()`; however each cut would require recomputing\n",
    "the clustering. Similarly, trees may be cut by distance threshold\n",
    "with an argument of `distance_threshold` to `HClust()`\n",
    "or `height` to `cut_tree()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd1f13-1169-4f0c-85a5-389e33c31f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_tree(linkage_comp, height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3393b511-7d35-4e61-8d4d-b0a8819b8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the variables before performing hierarchical clustering of the observations (use StandardScaler())\n",
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "hc_comp_scale = HClust(distance_threshold=0,\n",
    "                       n_clusters=None,\n",
    "                       linkage='complete').fit(X_scale)\n",
    "linkage_comp_scale = compute_linkage(hc_comp_scale)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "dendrogram(linkage_comp_scale, ax=ax, **cargs)\n",
    "ax.set_title(\"Hierarchical Clustering with Scaled Features\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fd0561-100c-4a2d-9262-c215b9fe3203",
   "metadata": {},
   "source": [
    "Correlation-based distances between observations can be used for\n",
    "clustering. The correlation between two observations measures the\n",
    "similarity of their feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800033f4-3c2a-47b3-9f88-d43aa7af6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.standard_normal((30, 3))\n",
    "corD = 1 - np.corrcoef(X)\n",
    "hc_cor = HClust(linkage='complete',\n",
    "                distance_threshold=0,\n",
    "                n_clusters=None,\n",
    "                metric='precomputed')\n",
    "hc_cor.fit(corD)\n",
    "linkage_cor = compute_linkage(hc_cor)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "dendrogram(linkage_cor, ax=ax, **cargs)\n",
    "ax.set_title(\"Complete Linkage with Correlation-Based Dissimilarity\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30d246-fa3f-4ddb-8762-5776f748be78",
   "metadata": {},
   "source": [
    "*These exercises were adapted from :* James, Gareth, et al. An Introduction to Statistical Learning: with Applications in Python, Springer, 2023."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "497a84dc8fec8cf8d24e7e87b6d954c9a18a327edc66feb9b9ea7e9e72cc5c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
