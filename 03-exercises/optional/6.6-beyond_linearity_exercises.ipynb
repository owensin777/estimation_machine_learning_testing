{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21188dbb-5da2-4d88-b878-3164d46a1755",
   "metadata": {},
   "source": [
    "# 6.6: Beyond Linearity Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680c15cc-6bb5-4aff-8b34-75541a59349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our libraries and objects\n",
    "import numpy as np, pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (summarize,\n",
    "                         poly,\n",
    "                         ModelSpec as MS)\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from pygam import (s as s_gam,\n",
    "                   l as l_gam,\n",
    "                   f as f_gam,\n",
    "                   LinearGAM,\n",
    "                   LogisticGAM)\n",
    "\n",
    "from ISLP.transforms import (BSpline,\n",
    "                             NaturalSpline)\n",
    "from ISLP.models import bs, ns\n",
    "from ISLP.pygam import (approx_lam,\n",
    "                        degrees_of_freedom,\n",
    "                        plot as plot_gam,\n",
    "                        anova as anova_gam)\n",
    "import warnings\n",
    "# Suppress FutureWarning in ISLP.models.columns\n",
    "# The warning is related to Series.__getitem__ treating keys as positions, which is deprecated.\n",
    "# Since ISLP is an external library that I don't control, and this specific warning does not\n",
    "# affect my current usage, I'm suppressing it to keep the output clean and focused on relevant information.\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='ISLP.models.columns')\n",
    "\n",
    "# Load data\n",
    "Wage = load_data('Wage')\n",
    "y = Wage['wage']\n",
    "age = Wage['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c612c-f52b-4cb9-aa45-8a1c6f93ab4f",
   "metadata": {},
   "source": [
    "### Polynomial Regression\n",
    "\n",
    "We'll use the `poly()` function to create a model matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5516e-99ba-4145-8bfa-9c37d83b07a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_age = MS([poly('age', degree=4)]).fit(Wage)\n",
    "M = sm.OLS(y, poly_age.transform(Wage)).fit()\n",
    "summarize(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8267ee-7cbb-4d23-aa71-9ab391062612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of values for `age` at which we want predictions.\n",
    "age_grid = np.linspace(age.min(),\n",
    "                       age.max(),\n",
    "                       100)\n",
    "age_df = pd.DataFrame({'age': age_grid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4a303-5c2c-4a12-8e78-132e72440f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to plot the data and add the fit from the fourth-degree polynomial\n",
    "def plot_wage_fit(age_df, \n",
    "                  basis,\n",
    "                  title):\n",
    "\n",
    "    X = basis.transform(Wage)\n",
    "    Xnew = basis.transform(age_df)\n",
    "    M = sm.OLS(y, X).fit()\n",
    "    preds = M.get_prediction(Xnew)\n",
    "    bands = preds.conf_int(alpha=0.05)\n",
    "    fig, ax = subplots(figsize=(8,8))\n",
    "    ax.scatter(age,\n",
    "               y,\n",
    "               facecolor='gray',\n",
    "               alpha=0.5)\n",
    "    for val, ls in zip([preds.predicted_mean,\n",
    "                      bands[:,0],\n",
    "                      bands[:,1]],\n",
    "                     ['b','r--','r--']):\n",
    "        ax.plot(age_df.values, val, ls, linewidth=3)\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_xlabel('Age', fontsize=20)\n",
    "    ax.set_ylabel('Wage', fontsize=20);\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108727c-bc49-4d77-9c36-e304fbb83950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot\n",
    "plot_wage_fit(age_df, \n",
    "              poly_age,\n",
    "              'Degree-4 Polynomial');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0e95d-eafc-4eab-83fa-32a68702f73f",
   "metadata": {},
   "source": [
    "We now fit a series of models ranging from linear (degree-one) to degree-five polynomials, and look to determine the simplest model that is sufficient to explain the relationship between wage and age. We use the `anova_lm()` function, which performs a series of ANOVA tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9bc2ea-8468-428e-8d78-c403d52a5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [MS([poly('age', degree=d)]) \n",
    "          for d in range(1, 6)]\n",
    "Xs = [model.fit_transform(Wage) for model in models]\n",
    "anova_lm(*[sm.OLS(y, X_).fit()\n",
    "           for X_ in Xs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e84893-d31c-4d3b-9ef8-211204ee111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18bdfe-7f66-4db0-bacb-a01798c444a7",
   "metadata": {},
   "source": [
    "Notice that the p-values are the same, and in fact the square of the t-statistics are equal to the F-statistics from the `anova_lm()` function\n",
    "\n",
    "An alternative to the Anova method is to use cross-validation. \n",
    "\n",
    "**Describe the steps you would take to perform cross-validation in this case to choose the degree of the polynomial.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a99823-3758-440a-8e5a-2c9517bf38d3",
   "metadata": {},
   "source": [
    "### Step Function\n",
    "\n",
    "We will now try to fit a step function to the data in order to again predict wage based on age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676b40d-a8a3-4e45-89d1-cb826e416d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = poly_age.transform(Wage)\n",
    "high_earn = Wage['high_earn'] = y > 250 # shorthand\n",
    "glm = sm.GLM(y > 250,\n",
    "             X,\n",
    "             family=sm.families.Binomial())\n",
    "B = glm.fit()\n",
    "summarize(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc81a89-6f71-4147-a5a7-84da7e04153b",
   "metadata": {},
   "source": [
    "The intercept coefficient can be interpreted as the average salary for individuals age < 34. The remaining\n",
    "coefficients are the average additional salary for those in the other age groups.\n",
    "**Make wage predictions for a range of ages and plot the results including the 95% confidence intervals.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94a1f8-84d5-40df-8317-3c13e2f975e2",
   "metadata": {},
   "source": [
    "### Splines\n",
    "\n",
    "We want to fit a regression spline with wage as the response and age as the predictor. In order to fit regression splines, we use transforms from the `ISLP` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73587c21-0ce5-4565-89d1-0ae0a5e55292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, the B-splines produced are cubic. To change the degree, use the argument degree\n",
    "bs_ = BSpline(internal_knots=[25,40,60], intercept=True).fit(age)\n",
    "bs_age = bs_.transform(age)\n",
    "bs_age.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d5598-9c04-4c82-86f5-497816c827cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now fit a cubic spline model to the Wage data\n",
    "bs_age = MS([bs('age', internal_knots=[25,40,60])])\n",
    "Xbs = bs_age.fit_transform(Wage)\n",
    "M = sm.OLS(y, Xbs).fit()\n",
    "summarize(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2a484-2c8a-4290-9ef5-1e1fef7f1db4",
   "metadata": {},
   "source": [
    "In order to fit a natural spline, we use the `NaturalSpline()` transform with the corresponding helper `ns()`. Here we fit a natural spline with five degrees of freedom (excluding the intercept) and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452df86-acb0-425f-8e17-64534df4deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_age = MS([ns('age', df=5)]).fit(Wage)\n",
    "M_ns = sm.OLS(y, ns_age.transform(Wage)).fit()\n",
    "summarize(M_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40f5be-bd7f-4d88-996a-c68753efd3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plot_wage_fit(age_df,\n",
    "              ns_age,\n",
    "              'Natural spline, df=5');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6496949c-203d-4e91-b6bd-2b5dc48bdc95",
   "metadata": {},
   "source": [
    "### Local Regression\n",
    "\n",
    "We illustrate the use of local regression using the `lowess()` function from `sm.nonparametric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d29b49-1741-46de-885f-25b8a96f2f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowess = sm.nonparametric.lowess\n",
    "fig, ax = subplots(figsize=(8,8))\n",
    "ax.scatter(age, y, facecolor='gray', alpha=0.5)\n",
    "for span in [0.2, 0.5]:\n",
    "    fitted = lowess(y,\n",
    "                    age,\n",
    "                    frac=span,\n",
    "                    xvals=age_grid)\n",
    "    ax.plot(age_grid,\n",
    "            fitted,\n",
    "            label='{:.1f}'.format(span),\n",
    "            linewidth=4)\n",
    "ax.set_xlabel('Age', fontsize=20)\n",
    "ax.set_ylabel('Wage', fontsize=20);\n",
    "ax.legend(title='span', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7933f0d-e771-4383-8ccc-4679b18e0d34",
   "metadata": {},
   "source": [
    "**Redo the fitting and plotting but this time choose a smaller span. What differences do you\n",
    "see? Explain why choosing a smaller span causes this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd4eb6-99fc-477e-9db7-db2403d1dc55",
   "metadata": {},
   "source": [
    "### Generalised Additive Models\n",
    "We will fit a GAM to predict Wage using the predictors year, age, and education. The quantitative\n",
    "predictors will be a natural spline functions and education will naturally be fit with a step function.\n",
    "\n",
    "To fit GAMs in Python we will use the `pygam` package which can be installed via `pip install pygam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d212d181-784b-46fa-a979-ab41fcfbed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_age = np.asarray(age).reshape((-1,1))\n",
    "gam = LinearGAM(s_gam(0, lam=0.6))\n",
    "gam.fit(X_age, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d09c8d-181e-4f2b-88ee-3b65f9ba85ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model matrix\n",
    "ns_age = NaturalSpline(df=4).fit(age)\n",
    "ns_year = NaturalSpline(df=5).fit(Wage['year'])\n",
    "Xs = [ns_age.transform(age),\n",
    "      ns_year.transform(Wage['year']),\n",
    "      pd.get_dummies(Wage['education']).values]\n",
    "X_bh = np.hstack(Xs)\n",
    "gam_bh = sm.OLS(y, X_bh).fit()\n",
    "\n",
    "# Construct partial dependence plots\n",
    "age_grid = np.linspace(age.min(),\n",
    "                       age.max(),\n",
    "                       100)\n",
    "X_age_bh = X_bh.copy()[:100]\n",
    "X_age_bh[:] = X_bh[:].mean(0)[None,:]\n",
    "X_age_bh[:,:4] = ns_age.transform(age_grid)\n",
    "preds = gam_bh.get_prediction(X_age_bh)\n",
    "bounds_age = preds.conf_int(alpha=0.05)\n",
    "partial_age = preds.predicted_mean\n",
    "center = partial_age.mean()\n",
    "partial_age -= center\n",
    "bounds_age -= center\n",
    "fig, ax = subplots(figsize=(8,8))\n",
    "ax.plot(age_grid, partial_age, 'b', linewidth=3)\n",
    "ax.plot(age_grid, bounds_age[:,0], 'r--', linewidth=3)\n",
    "ax.plot(age_grid, bounds_age[:,1], 'r--', linewidth=3)\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Effect on wage')\n",
    "ax.set_title('Partial dependence of age on wage', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254765b-3580-441f-a4d0-7ff96f2c5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at effect of year on wage\n",
    "year_grid = np.linspace(2003, 2009, 100)\n",
    "year_grid = np.linspace(Wage['year'].min(),\n",
    "                        Wage['year'].max(),\n",
    "                        100)\n",
    "X_year_bh = X_bh.copy()[:100]\n",
    "X_year_bh[:] = X_bh[:].mean(0)[None,:]\n",
    "X_year_bh[:,4:9] = ns_year.transform(year_grid)\n",
    "preds = gam_bh.get_prediction(X_year_bh)\n",
    "bounds_year = preds.conf_int(alpha=0.05)\n",
    "partial_year = preds.predicted_mean\n",
    "center = partial_year.mean()\n",
    "partial_year -= center\n",
    "bounds_year -= center\n",
    "fig, ax = subplots(figsize=(8,8))\n",
    "ax.plot(year_grid, partial_year, 'b', linewidth=3)\n",
    "ax.plot(year_grid, bounds_year[:,0], 'r--', linewidth=3)\n",
    "ax.plot(year_grid, bounds_year[:,1], 'r--', linewidth=3)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Effect on wage')\n",
    "ax.set_title('Partial dependence of year on wage', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65043539-da27-4cfc-bb9d-e89214bf4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepations\n",
    "gam_full = LinearGAM(s_gam(0) +\n",
    "                     s_gam(1, n_splines=7) +\n",
    "                     f_gam(2, lam=0))\n",
    "Xgam = np.column_stack([age,\n",
    "                        Wage['year'],\n",
    "                        Wage['education'].cat.codes])\n",
    "gam_full = gam_full.fit(Xgam, y)\n",
    "\n",
    "# Looking at education \n",
    "fig, ax = subplots(figsize=(8, 8))\n",
    "ax = plot_gam(gam_full, 2)\n",
    "ax.set_xlabel('Education')\n",
    "ax.set_ylabel('Effect on wage')\n",
    "ax.set_title('Partial dependence of wage on education',\n",
    "             fontsize=20);\n",
    "ax.set_xticklabels(Wage['education'].cat.categories, fontsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67481f16-69d4-4b6b-bf64-65f53f8dd6fc",
   "metadata": {},
   "source": [
    "We can see from the plot that wage is increasing somewhat linearly with year. **Use an ANOVA test to\n",
    "determine which of these three models is the best:**\n",
    "\n",
    "- The same GAM as before except exclude year.\n",
    "- The same GAM as before except it instead has a linear function of year (written simply + year)\n",
    "- The GAM we have already fit.\n",
    "\n",
    "**Recall that the models must be supplied to the anova() function in order of increasing complexity.\n",
    "Once you have determined which model is the best, plot the relationships as we did before.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e927463-8ba1-45cb-8532-965241ae8419",
   "metadata": {},
   "source": [
    "To fit a logistic regression GAM, we use `LogisticGAM()` from pygam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa2ca9-3f14-40f8-81bf-8e740802b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "age_term = gam.terms[0]\n",
    "lam_4 = approx_lam(X_age, age_term, 4)\n",
    "age_term.lam = lam_4\n",
    "degrees_of_freedom(X_age, age_term)\n",
    "\n",
    "# Logistic regression\n",
    "gam_logit = LogisticGAM(age_term + \n",
    "                        l_gam(1, lam=0) +\n",
    "                        f_gam(2, lam=0))\n",
    "gam_logit.fit(Xgam, high_earn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b38821-bcde-4015-8275-3af0420a929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = subplots(figsize=(8, 8))\n",
    "ax = plot_gam(gam_logit, 2)\n",
    "ax.set_xlabel('Education')\n",
    "ax.set_ylabel('Effect on wage')\n",
    "ax.set_title('Partial dependence of wage on education',\n",
    "             fontsize=20);\n",
    "ax.set_xticklabels(Wage['education'].cat.categories, fontsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d7925-c38e-4ba5-a45d-a0d3d7a86caa",
   "metadata": {},
   "source": [
    "The model seems to be very flat, with especially high error bars for the first category. Let's look at the data a bit more closely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da46a9bc-7f15-42eb-971c-cccab588e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(Wage['high_earn'], Wage['education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42177c-0c30-4718-9499-df8178f2210b",
   "metadata": {},
   "source": [
    "We see that there are no high earners in the first category of education, meaning that the model will have a hard time fitting. We will fit a logistic regression GAM excluding all observations falling into this category. This provides more sensible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1abc9-d696-43b9-85b2-adcfbd921a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep / refit\n",
    "age_term = gam_full.terms[0]\n",
    "age_term.lam = approx_lam(Xgam, age_term, df=4+1)\n",
    "year_term = gam_full.terms[1]\n",
    "year_term.lam = approx_lam(Xgam, year_term, df=4+1)\n",
    "gam_full = gam_full.fit(Xgam, y)\n",
    "\n",
    "only_hs = Wage['education'] == '1. < HS Grad'\n",
    "Wage_ = Wage.loc[~only_hs]\n",
    "Xgam_ = np.column_stack([Wage_['age'],\n",
    "                         Wage_['year'],\n",
    "                         Wage_['education'].cat.codes-1])\n",
    "high_earn_ = Wage_['high_earn']\n",
    "\n",
    "# Now we fit the model\n",
    "gam_logit_ = LogisticGAM(age_term +\n",
    "                         year_term +\n",
    "                         f_gam(2, lam=0))\n",
    "gam_logit_.fit(Xgam_, high_earn_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1897b-2e55-4e34-be85-b95abf43917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = subplots(figsize=(8, 8))\n",
    "ax = plot_gam(gam_logit_, 2)\n",
    "ax.set_xlabel('Education')\n",
    "ax.set_ylabel('Effect on wage')\n",
    "ax.set_title('Partial dependence of high earner status on education', fontsize=20);\n",
    "ax.set_xticklabels(Wage['education'].cat.categories[1:],\n",
    "                   fontsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4b099c-f776-4d1a-829c-ec95555edb60",
   "metadata": {},
   "source": [
    "*These exercises were adapted from :* James, Gareth, et al. An Introduction to Statistical Learning: with Applications in Python, Springer, 2023."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
