{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2d65d0f-c2a0-462e-9f37-96917af2dcb1",
   "metadata": {},
   "source": [
    "# 6.3: Classification Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb710870-1b5c-4338-9457-e2d8582b8c9c",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "### Import Libraries \n",
    "\n",
    "We import our standard libraries and specific objects/libraries at the top level of our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13747451-369c-4b0b-9366-3fb829982ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and objects\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize)\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') # mute warning messages\n",
    "from ISLP import confusion_table\n",
    "from ISLP.models import contrast\n",
    "from sklearn.discriminant_analysis import \\\n",
    "     (LinearDiscriminantAnalysis as LDA,\n",
    "      QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faad588-7276-4949-9742-a5b45f7646d0",
   "metadata": {},
   "source": [
    "First, load our `Smarket` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066a916-ed0b-49ee-aad4-ec07d0d4fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smarket = load_data('Smarket')\n",
    "Smarket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f638ab4-4681-48cf-8edc-f441ff7bdbda",
   "metadata": {},
   "source": [
    "We can view the variables names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182787f-eeb5-4826-a928-fd48442bd248",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smarket.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a67d43d-556e-4a01-9c0b-62be96a5ee42",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c8437-fc98-462f-b136-313ce87d670e",
   "metadata": {},
   "source": [
    "We will fit a logistic regression model in order to predict `Direction` using `Lag1` through `Lag5` and `Volume`. The `sm.GLM()` function fits generalized linear models, a class of models that includes logistic regression. Alternatively, the function `sm.Logit()` fits a logistic regression model directly. The syntax of `sm.GLM()` is similar to that of `sm.OLS()`, except that we use the argument `family=sm.families.Binomial()` in order to tell `statsmodels` to run a logistic regression rather than some other type of generalized linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190419db-09fd-47b7-87cd-9bb69596b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "allvars = Smarket.columns.drop(['Today', 'Direction', 'Year'])\n",
    "design = MS(allvars)\n",
    "X = design.fit_transform(Smarket)\n",
    "y = Smarket.Direction == 'Up'\n",
    "glm = sm.GLM(y,\n",
    "             X,\n",
    "             family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "summarize(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7748e7e-9d60-436f-a57f-924a5acc566d",
   "metadata": {},
   "source": [
    "The column labelled Pr(>|z|) gives the $p$-values associated with each variables. Recall that the $p$-values\n",
    "indicate whether or not to reject the null hypothesis that there is no association between the response and\n",
    "predictor variable. **Is there evidence of an association between any of the predictor variables and the response?\n",
    "If so, which ones?**\n",
    "\n",
    "The smallest $p$-value here is associated with `Lag1`. The negative coefficient for this predictor suggests that if the market had a positive return yesterday, then it is less likely to go up today. \n",
    "\n",
    "We use the `params` attribute of results in order to access just the coefficients for this fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d99c13-6e65-4d05-8e45-5a31c755e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f05df7-fe13-4c5d-b153-c476b48af7db",
   "metadata": {},
   "source": [
    "Likewise we can use the `pvalues` attribute to access the $p$-values for the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f0024-b3a9-4226-bc46-5c76e9952e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b003a7e9-1c21-41c7-8c70-e136fc4f66ce",
   "metadata": {},
   "source": [
    "The `predict()` method of results can be used to predict the probability that the market will go up, given values of the predictors. This method returns predictions on the probability scale. If no data set is supplied to the `predict()` function, then the probabilities are computed for the training data that was used to fit the logistic regression model. As with linear regression, one can pass an optional `exog` argument consistent with a design matrix if desired. Here we have printed only the first ten probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd554b6-b3e6-46d0-bb9a-ccd40f783fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = results.predict()\n",
    "probs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2be8825-4400-4b21-9874-9d5ef17fa1d8",
   "metadata": {},
   "source": [
    "In order to make a prediction as to whether the market will go up or down on a particular day, we must convert these predicted probabilities into class labels, `Up` or `Down`. The following two commands create a vector of class predictions based on whether the predicted probability of a market increase is greater than or less than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917c6c6-92cc-41c4-a044-ee16e5cf078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(['Down']*1250)\n",
    "labels[probs>0.5] = \"Up\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9746cb09-05c6-4d07-a992-054464c1d7ed",
   "metadata": {},
   "source": [
    "The `confusion_table()` function from the `ISLP` package summarizes these predictions, showing how many observations were correctly or incorrectly classified. Our function, which is adapted from a similar function in the module `sklearn.metrics`, transposes the resulting matrix and includes row and column labels. The `confusion_table()` function takes as first argument the predicted labels, and second argument the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afd9f0-2035-4adc-8bf1-a43a3e2591e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_table(labels, Smarket.Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7713746f-3d54-431b-9324-e4a650399220",
   "metadata": {},
   "source": [
    "The diagonal elements of the confusion matrix indicate correct predictions, while the off-diagonals represent incorrect predictions. Hence our model correctly predicted that the market would go up on 507 days and that it would go down on 145 days, for a total of 507 + 145 = 652 correct predictions. The `np.mean()` function can be used to compute the fraction of days for which the prediction was correct. In this case, logistic regression correctly predicted the movement of the market 52.2% of the time and 47.8% is the training error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f65a3f0-446d-45da-b421-d09dfb0a70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(507+145)/1250, np.mean(labels == Smarket.Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0711-503e-470d-a7a9-da2c0b5b3613",
   "metadata": {},
   "source": [
    "Now we can try predicting the outcomes of the test data. **Try this out yourselves! Find the confusion matrix and test error rate as well.**\n",
    "\n",
    "\n",
    "**How does the training error rate compare to the test error rate?**\n",
    "\n",
    "\n",
    "**Is logistic regression method good at predicting the direction of the market? Why or why not?\n",
    "Use the training/testing error rate to support your answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b827f-55db-4b7d-baae-1aca2332b02c",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis\n",
    "We begin by performing LDA on the Smarket data, using the function `LinearDiscriminantAnalysis()`, which we have abbreviated `LDA()`. We fit the model using only the observations before 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb0aa4-6f99-42cb-ac9d-7179a68d66af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous code to set up for LDA\n",
    "model = MS(['Lag1', 'Lag2']).fit(Smarket)\n",
    "\n",
    "X = model.transform(Smarket)\n",
    "D = Smarket.Direction\n",
    "train = (Smarket.Year < 2005)\n",
    "L_train, L_test = D.loc[train], D.loc[~train]\n",
    "\n",
    "X_train, X_test = X.loc[train], X.loc[~train]\n",
    "y_train, y_test = y.loc[train], y.loc[~train]\n",
    "\n",
    "glm_train = sm.GLM(y_train,\n",
    "                   X_train,\n",
    "                   family=sm.families.Binomial())\n",
    "results = glm_train.fit()\n",
    "probs = results.predict(exog=X_test)\n",
    "\n",
    "labels = np.array(['Down']*252)\n",
    "labels[probs>0.5] = 'Up'\n",
    "confusion_table(labels, L_test)\n",
    "\n",
    "newdata = pd.DataFrame({'Lag1':[1.2, 1.5],\n",
    "                        'Lag2':[1.1, -0.8]});\n",
    "newX = model.transform(newdata)\n",
    "results.predict(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67146e-017a-4f27-a5cd-eaf9fd3d53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(store_covariance=True)\n",
    "\n",
    "X_train, X_test = [M.drop(columns=['intercept'])\n",
    "                   for M in [X_train, X_test]]\n",
    "lda.fit(X_train, L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bdda75-2ce9-4756-a53b-acaf34aaa25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the means in the two classes \n",
    "lda.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537ab01-81b3-4472-9387-b415c4d34672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate prior probabilities \n",
    "lda.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f665f8-f56f-4fd6-bcdb-34e331afe79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get priors\n",
    "lda.priors_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb69742-67c9-4b2d-a229-040fd60f44b6",
   "metadata": {},
   "source": [
    "The LDA output indicates that $\\hat\\pi_{Down}=0.492$ and\n",
    "$\\hat\\pi_{Up}=0.508$.\n",
    "\n",
    "The LDA and logistic regression predictions are almost identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f81e5-acb6-42c5-93bd-b9e853b435e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pred = lda.predict(X_test)\n",
    "\n",
    "confusion_table(lda_pred, L_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be1fa3-e1d3-4eab-8927-0e6d93764047",
   "metadata": {},
   "source": [
    "**Try fitting a LDA model using predictor variables of the Smarket data of your choice. Discuss\n",
    "the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ccaa5-3daa-4110-9cdd-77037fe2b3b5",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis\n",
    "\n",
    "We will now fit a QDA model to the  `Smarket`  data. QDA is\n",
    "implemented via\n",
    "`QuadraticDiscriminantAnalysis()`\n",
    "in the `sklearn` package, which we abbreviate to `QDA()`.\n",
    "The syntax is very similar to `LDA()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59decc0-9b57-449e-9c20-af28d8acac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QDA(store_covariance=True)\n",
    "qda.fit(X_train, L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c3565b-9dcd-4a3c-87b9-ed1e11f58b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute means and priors\n",
    "qda.means_, qda.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e11f24-8883-41c9-99b5-8afad9cbe98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate covariance\n",
    "qda.covariance_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152cb5ce-7763-4a07-b9fe-4513f63156b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "qda_pred = qda.predict(X_test)\n",
    "confusion_table(qda_pred, L_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01cde19-d2ae-4e8c-8be4-46f1db259906",
   "metadata": {},
   "source": [
    "The QDA predictions are accurate almost 60% of the time, even though the 2005 data was not used to fit the model. The test error rate of the QDA model is 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c5ba1-ca1a-4528-9df6-3cb2b1ab092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(qda_pred == L_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f884e-6c02-4305-9258-714017b3c79c",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Next, we fit a naive Bayes model to the `Smarket` data, which is\n",
    "similar to `LDA()` and `QDA()`. By\n",
    "default, this implementation `GaussianNB()` of the naive Bayes classifier models each\n",
    "quantitative feature using a Gaussian distribution. However, a kernel\n",
    "density method can also be used to estimate the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cfbb5f-f3be-4871-b48f-5919b317068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = GaussianNB()\n",
    "NB.fit(X_train, L_train)\n",
    "\n",
    "NB.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb54b4-f0da-41e5-88c6-27b556b5c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "nb_labels = NB.predict(X_test)\n",
    "confusion_table(nb_labels, L_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a080c3-90b5-4306-9543-927f515d46e3",
   "metadata": {},
   "source": [
    "Naive Bayes performs well on these data, with accurate predictions over 59% of the time. This is slightly worse than QDA, but much better than LDA. The test error rate of the naive Bayes model is 41%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22702b-5b0d-432a-b9ac-600600392fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate probabilities\n",
    "NB.predict_proba(X_test)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8eb8a3-1f5b-47d5-83e7-f1d1df516f0d",
   "metadata": {},
   "source": [
    "**Try fitting a naive Bayes model using predictor variables of the Smarket data of your choice.\n",
    "Discuss the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a3d6e4-ff46-4fdf-9730-7c0c457c5339",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "\n",
    "We will now perform KNN using the `KNeighborsClassifier()` function. This function is similar\n",
    "to the other model-fitting functions we've used throughout these exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18870a9-9be9-4ebf-8781-0875f2ae835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "X_train, X_test = [np.asarray(X) for X in [X_train, X_test]]\n",
    "knn1.fit(X_train, L_train)\n",
    "knn1_pred = knn1.predict(X_test)\n",
    "confusion_table(knn1_pred, L_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cea554-fd9e-4c92-85f6-c656aa321589",
   "metadata": {},
   "source": [
    "The results using $K=1$ are not very good, since only $50%$ of the\n",
    "observations are correctly predicted. Of course, it may be that $K=1$\n",
    "results in an overly-flexible fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a360d4a-e304-4431-9cf5-2516f00e3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "(83+43)/252, np.mean(knn1_pred == L_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f4213-f6fc-47ca-8f3c-771c8a0843d3",
   "metadata": {},
   "source": [
    "As we can see KNN for $K=1$ only gives 50% accuracy which is no better than random chance. \n",
    "\n",
    "**Try running\n",
    "KNN for several values of K and summarize the results for the best model you find.\n",
    "Out of all the classification methods we tried, which performs best on the Smarket data? Give\n",
    "some explanation for why that might be.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11670164-eea7-4dd7-b672-9ee883467af6",
   "metadata": {},
   "source": [
    "*These exercises were adapted from :* James, Gareth, et al. An Introduction to Statistical Learning: with Applications in Python, Springer, 2023."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "497a84dc8fec8cf8d24e7e87b6d954c9a18a327edc66feb9b9ea7e9e72cc5c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
