{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db0d7a3-39b9-4498-85cb-d9d75f914304",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc97cd7-933f-4bac-804a-1f2cf85ebad6",
   "metadata": {},
   "source": [
    "This assignment is due on __Wednesday March 20, by 11:59PM\t__. It pertains to content taught in classes 4-5.\n",
    "\n",
    "This assignment should be completed in Python, and an PDF file should be submitted, containing both code and written answers. If you like, you may create your own Jupyter Notebook file from scratch, but it is likely easier to modify this one.\n",
    "\n",
    "As before, questions that require identification and/or interpretation will not penalized for brevity of response: if a question can be answered with 'yes/no', or a numeric value, you may simply state as much. If you incorporate code from the internet (which is not required and generally not advisable), please cite the source within your code (providing a URL is sufficient).\n",
    "\n",
    "If you like, you may collaborate with others in the class. If you choose to do so, please indicate with whom you have worked at the top of your PDF. Separate submissions are required.\n",
    "\n",
    "Any questions can be addressed to Kamilah ([kamilah.ebrahim@mail.utoronto.ca]()) and/or Ananya ([ananya.jha@mail.utoronto.ca]()) and/or Vishnou ([vishnouvina@cs.toronto.edu]()) before the due-date. Please submit your assignments through your Drive Folder.\n",
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589d262b-0089-4b1a-821d-d55570e0d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Import specific objects\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence \\\n",
    "     import variance_inflation_factor as VIF\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "%pip install l0bnb\n",
    "from l0bnb import fit_path\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)\n",
    "\n",
    "# Install, import, and load specific package\n",
    "%pip install faraway > nul 2>&1 # \"> nul 2>&1\" means that the install messages have been surpressed\n",
    "import faraway as fw\n",
    "import faraway.datasets.fat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21283675-9b75-4413-89c2-0890ceb198b8",
   "metadata": {},
   "source": [
    "### Question 1: Regularization via best subset selection\n",
    "\n",
    "First, we'll use the `swiss` dataset, which is a built-in dataset in R, but can be added to Python. As always, start by reviewing a description of the dataset, by typing `swiss?` in the console.  To perform model selection via \"best subsets\", we will use the `regsubsets` function in the `leaps` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3824c-e20a-4709-b7e1-a094bd0841c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "swiss = sm.datasets.get_rdataset(\"swiss\")\n",
    "df = pd.DataFrame(swiss.data)\n",
    "\n",
    "# Explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3473b2bf-8f6b-4370-8d96-1def6e2ee7cf",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "\n",
    "_(i)_ What will be the size (number of observations) of each LOOCV training sample?\n",
    "\n",
    "_(ii)_ What will be the size (number of observations) of each LOOCV testing sample?\n",
    "\n",
    "_(iii)_ How many \"folds\" (i.e., k) will our LOOCV model have?  \n",
    "\n",
    "_(iv)_ Now, fit a linear model, with `Fertility` as the response variable, and all other variables as predictors. Use the `sm.OLS` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb0abf7-57e2-447c-8f2a-98838401a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392e58fe-2bf9-44f1-8184-494d4d52b79c",
   "metadata": {},
   "source": [
    "_(v)_ Next, perform LOOCV, using the appropriate function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0773d418-870f-4122-bbf0-3fa5f26523ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76f1994-6d3f-4aa9-8288-5ecd385315bd",
   "metadata": {},
   "source": [
    "_(vi)_ What is the MSE for the LOOCV?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a807b1e0-821b-4bb6-851b-c0ce1d197f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb482a-1a25-4370-b8e7-5497ca5baff1",
   "metadata": {},
   "source": [
    "_(vii)_ Run the LOOCV for a second time (no need to repeat the code; simply, run your existing code in in v and vi again). Do you obtain different results? Why or why not?  \n",
    "\n",
    "_(viii)_ Manually compute MSE for the linear model (without LOOCV) that you fit with the `sm.OLS` function, in iv. (Hint: recall that MSE is defined as the sum of squared residuals, divided by n. You can \"look inside\" your linear model object to find residual values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd956ff-1d69-4500-b116-9319958eab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f5506-6637-4fbd-994c-0b363082a2cf",
   "metadata": {},
   "source": [
    "_(ix)_ Does the LOOCV-linear model, or the non-validated linear model, appear to have greater error? Why might this be the case?   \n",
    "\n",
    "Imagine that the `swiss` dataset has just announced a major new release, which will include data from all provinces of Europe (not just those in Switzerland), and records all the way to the present day (not just 1888).  \n",
    "\n",
    "_(x)_ Would you choose LOOCV as a validation method for this new release? Why or why not?  \n",
    "\n",
    "_(xi)_ What validation method might you choose instead?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f0fcc-6d69-4a50-80a5-d66dcf3b991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6bb34-01e7-4fed-afcc-171827e4b30d",
   "metadata": {},
   "source": [
    "### Question 2: Regularization via best subset selection\n",
    "\n",
    "Now, let's use the `fat` dataset, in the `faraway` library. Please make sure you have installed the `faraway` library and loaded specific objects listed at the start of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7cfb9-e721-495b-874a-4930fcb85976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "fat = faraway.datasets.fat.load()\n",
    "fat\n",
    "\n",
    "# Explore dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0a547-a661-4953-93c2-1d851b5b906b",
   "metadata": {},
   "source": [
    "_(i)_ Using the `l0bnb` library, fit a best subset model with `brozek` (body fat) as the response, and all variables except for `free`, `siri`, and `density` as predictors. Provide the `nvmax` argument, with a value equal to the number of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d4f3d-5c0f-46a9-8a87-e513a9f94beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6eaef7-44fe-497a-a147-63df65ef0a5d",
   "metadata": {},
   "source": [
    "The plot below shows (unadjusted) $R^2$ estimates for all subset models.\n",
    "\n",
    "![](https://drive.google.com/uc?id=1omSUpJrARF6gYnZ2hWv61EWbdlWklBdG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e74cc-7a03-4828-a548-109f46f32cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code\n",
    "\n",
    "# plt.plot(best_sub['num_vars'], best_sub['rsq'], marker='o', linestyle='-')\n",
    "# plt.xlabel('Number of Variables/Predictors')\n",
    "# plt.ylabel('R-squared value')\n",
    "# plt.title('R-squared vs Number of Variables/Predictors')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21426b-1409-41a1-a83f-b66ae7bae891",
   "metadata": {},
   "source": [
    "_(ii)_ Why can't we use (unadjusted) $R^2$ estimates to select the best model? \n",
    "\n",
    "_(iii)_ Create a plot similar to that above, but showing adjusted $R^2$. Add a coloured point, highlighting the number of variables/predictors with the most desirable adjusted $R^2$ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e248942-6284-40c2-85b5-6cd73f759a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a842b4-4fff-4aae-9ff6-14a7726cdc4d",
   "metadata": {},
   "source": [
    "_(iv)_  Write code to pull out the highest and lowest $R^2$ values (Hint: use the `max` and `min` functions.). Does the difference in percent variance explained (i.e., $R^2$) appear to be meaningful? (No statistics needed: interpret in the context of the `fat` dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13496de-4a12-4554-a84d-72d600928d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34735c0-7ad4-4ff9-8a34-c199b21df56b",
   "metadata": {},
   "source": [
    "_(v)_ What is the best model according to BIC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25fe5c-a660-4013-9ce9-0260961e6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9970f8af-0b30-4f3d-b60a-4a02d6bea7df",
   "metadata": {},
   "source": [
    "_(vi)_ What is the best model according to $C_p$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90ee40-095c-4181-ab6f-d30db316429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303cda10-24d4-45e6-9710-1367b3b482cd",
   "metadata": {},
   "source": [
    "_(vii)_ Are you surprised that BIC and $C_p$ compute differing estimates of prediction error? Why or why not?\n",
    "\n",
    "Let's be more rigorous, and compute a direct (cf. indirect) estimate of prediction error via k-fold cross validation. The `predict_regsubsets` function provided below achieves something comparable to `predict` (in brief, it extracts the fitted coefficients for each model size and then multiplies the corresponding predictors for each test observations). <u> This code does not need to be edited.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a602f4aa-096a-448c-9105-52686e17bd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_regsubsets(object, newdata, id):\n",
    "    form = object['call'][1]  # pull out the formula\n",
    "    mat = pd.get_dummies(newdata, drop_first=True)  # make a matrix\n",
    "    coefs = object['coef'][id]  # pull out coefficients\n",
    "    vars = list(coefs.keys())  # pull out associated predictors\n",
    "    result = np.dot(mat[vars], coefs)  # matrix multiplication\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b4bd9e-85c7-4eee-b67c-d237999787b2",
   "metadata": {},
   "source": [
    "Now, we need to define several variables/objects for our k-fold cross validation. In the code chunk below:  \n",
    "\n",
    "_(viii)_ Define a variable `k`, with a value of 5. \n",
    "\n",
    "_(ix)_ Define a variable `n`, with a value reflecting the number of observations in our data.\n",
    "\n",
    "_(x)_ Define a variable `p`, with a value reflecting the maximum number of predictors in our subset selection/\n",
    "\n",
    "_(xi)_ Define a variable `kfolds`. This variable is a vector, containing randomly selected integers from 1 through k, and should be of length n. (Hint: review the `sample` and `rep` functions.)\n",
    "\n",
    "_(xii)_ Define a variable `cv_error`. This variable is a matrix. Its number of rows should be equal to k, and it number of columns should be equal to p. (You may choose to fill the matrix with NAs or 0 values or something else; these will be overwritten.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4be629-54b0-4b5c-b663-953eb74f855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define k\n",
    "\n",
    "# define n\n",
    "\n",
    "# define p\n",
    "\n",
    "# define folds\n",
    "\n",
    "# define cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb706c-0f8a-4b49-b0d4-4415dc445ebf",
   "metadata": {},
   "source": [
    "Great! Now that we have our required variables/objects, and the (provided) `skm.cross_val_predict()` function, we must write a for loop that will (a) fit our model on all but the held-out (test) fold, (b) predict the response in the held-out fold, and compute MSE in the held-out fold.\n",
    "\n",
    "The image below shows most of this code, with some crucial bits occluded. The occluded bits are 5 variables defined above: `k`, `regsubsets`, `p`, `folds`, and `cv_error`. ![](https://drive.google.com/uc?id=1MdbaIhq82sU-230WX8qi1vR7T8hCJBV7)\n",
    "\n",
    "_(xiii)_ Type this code into the chunk below, filling in the missing bits. (You are free to omit comments and change the code structure -- as long as it works!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd89689-e5cc-41f9-934a-22264f82d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81dbd4-0013-49fb-ad8a-0ddd19c4c668",
   "metadata": {},
   "source": [
    "_(xiv)_ Review your `cv_error` matrix. It should contain 14 columns (one for each number of predictors) and 5 rows (one for each of the k-folds). The contained values are MSE estimates. Find the mean of the MSE estimates, for each number of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea153890-d13f-4cfd-a0f3-0f85c6a402d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb3d08c-e60f-4c31-8933-d27494375274",
   "metadata": {},
   "source": [
    "_(BONUS)_. The \"one-standard-error rule\" states that if there are several models with similar estimates of test MSE, we can choose between them by: (a) calculating the MSE standard error model (number of predictors), (b) consider all models with an MSE within one standard error of the model with the smallest MSE, and (c) from the models within this band, select the one with the smallest number of predictors. Perform computations over `cv_error` to select the ideal number of predictors, in accordance with the \"one-standard-error rule\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dcd11c-98a1-4cb6-9388-dac56b7c90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "497a84dc8fec8cf8d24e7e87b6d954c9a18a327edc66feb9b9ea7e9e72cc5c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
