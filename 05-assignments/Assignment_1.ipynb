{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0bcac6-5086-4f4e-928a-570a9ff7ae58",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce0350-2a17-4e93-8d4c-0b8748fdfc32",
   "metadata": {},
   "source": [
    "This assignment is due on __Sunday March 17, by 11:59PM__. It pertains to content taught in classes 1-3. \n",
    "\n",
    "This assignment should be completed in Python, and an PDF file should be submitted, containing both code and written answers. If you like, you may create your own Jupyter Notebook file from scratch, but it is likely easier to modify this one.\n",
    "\n",
    "Please do not be intimidated by the apparent length of this assignment (it is deceiving!). All required code is a single line. Questions that require identification and/or intepretation will not penalized for brevity of response: if a question can be answered with 'yes/no', or a numeric value, you may simply state as much. \n",
    "\n",
    "We will go through comparable code and concepts in class. If you run into trouble, start by using the help `help()` function in Python, to get information about the datasets and function in question. The internet is also a great resource when coding (though note that no outside searches are required by the assignment!). If you do incorporate code from the internet, please cite the source within your code (providing a URL is sufficient).\n",
    "\n",
    "Please bring questions that you cannot work out on your own to tutorial. We will work with you through the issue.\n",
    "\n",
    "If you like, you may collaborate with others in the class. If you choose to do so, please indicate with whom you have worked at the top of your PDF. Separate submissions are required.\n",
    "\n",
    "Any questions can be addressed to Kamilah ([kamilah.ebrahim@mail.utoronto.ca]()) and/or Ananya ([ananya.jha@mail.utoronto.ca]()) and/or Vishnou ([vishnouvina@cs.toronto.edu]()) before the due-date. Please submit your assignments through your Drive Folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5001c-7715-4ebe-b0f7-e4bd04349629",
   "metadata": {},
   "source": [
    "### Question 1: Simple Linear Regression \n",
    "\n",
    "Let's set up our workspace and use the `Boston` dataset in the `ISLP` library. Print `Boston` to learn more about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3485d6-ba58-4660-a983-5680821c5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import specific objects\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from statsmodels.stats.outliers_influence \\\n",
    "     import variance_inflation_factor as VIF\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431d282-f9ca-4d5d-8912-71ffc9d8ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the \"Boston\" dataset using the \"load_data\" function from the ISLP package\n",
    "Boston = load_data('Boston')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312cc4e-e77d-41c9-84ce-48384ca51984",
   "metadata": {},
   "source": [
    "Before we fit and review model outputs, we should visualize our data. Review the code and plot, shown below. Answer the following questions:\n",
    "\n",
    "_(i)_ What are the `medv` and `dis` variables being plotted? (Hint: review this [link](https://islp.readthedocs.io/en/latest/datasets/Boston.html))\n",
    "\n",
    "_(ii)_ What concept ‘defines’ the plotted line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486481b-e496-41f0-bc9c-a7073c82fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the variables\n",
    "medv = Boston['medv'].values.reshape(-1, 1)\n",
    "dis = Boston['dis'].values.reshape(-1, 1)\n",
    "\n",
    "# Plot data\n",
    "plt.scatter(dis, medv, label='Data')\n",
    "plt.xlabel('dis')\n",
    "plt.ylabel('medv')\n",
    "\n",
    "# Fit a linear regression model\n",
    "lm = LinearRegression()\n",
    "lm.fit(dis, medv)\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(dis, lm.predict(dis), color='red', label='Regression Line')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('dis')\n",
    "plt.ylabel('medv')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fb5ea2a-ee48-448c-a028-784236c1c999",
   "metadata": {},
   "source": [
    "Consider the variables plotted above. In the context of the `Boston` dataset:\n",
    "\n",
    "_(iii)_ What is the (implied) null hypothesis? What is the (implied) alternative hypothesis?\n",
    "\n",
    "_(iv)_ Now, let’s fit a simple regression model, using the general syntax `sm.OLS()` and `model.fit()`. As above, use `medv` as the response variable Y, and `dis` as the predictor variable X. (Hint: use the syntax `sm.add_constant` with the appropriate argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dbac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebacfc94-686d-4c5a-a2f3-15240f13d212",
   "metadata": {},
   "source": [
    "Review your model output to answer the following questions (Hint: use the `summary` and `conf_int` functions):    \n",
    "_(v)_ What are the _coefficient estimates_ for $B_0$ (intercept) and $B_1$ (slope)?  \n",
    "_(vi)_ What are the _standard errors_ for $B_0$ and $B_1$?  \n",
    "_(vii)_ What are the _confidence intervals_ for $B_0$ and $B_1$?  \n",
    "\n",
    "Now, let's interpret the model output.  \n",
    "_(viii)_ Is the model a good fit? (Hint: review $R^2$)  \n",
    "_(ix)_ Do we reject the (implied) null hypothesis? Why or why not? (Hint: review model $F$ statistic, $p$ value).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7116b-6a10-41be-85a3-9d11402f02bd",
   "metadata": {},
   "source": [
    "### Question 2: Multiple Linear Regression \n",
    "\n",
    "We'll continue to use the `Boston` dataset for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1e0bf-3c57-47c8-af30-464e6f584169",
   "metadata": {},
   "source": [
    "_(i)_ Fit a multiple linear regression, with two predictor variables: $X_1$ is `dis`, and $X_2$ is `rm`. As before, keep `medv` as the response variable Y. (Hint: use the syntax `sm.add_constant` with the appropriate arguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f4f97-5935-4cd5-a691-512d4b6a66c6",
   "metadata": {},
   "source": [
    "_(ii)_ In the context of the `Boston` dataset, state the null and alternative hypotheses.\n",
    "\n",
    "_(iii)_ Review the model output, using `summary()`. Does it appear that both `dis` and `rm` are predictive of `medv`? How did you determine this?\n",
    "\n",
    "_(iv)_ We can use the inbuilt `sm.graphics.plot_regress_exog` function to generate helpful diagnostic plots (Hint: provide `plot_regress_exog` with the multiple regression model). Review the first generated plot, 'Residuals vs. Fitted'. Which observations are outliers? What impact might outliers have on our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02726275-c15a-4629-9b2c-19184b0d9fbb",
   "metadata": {},
   "source": [
    "_(v)_ Fit a second model, this time including an interaction between the two predictor variables. Is there an interaction? (Hint: add a variable `x1 * x2` where `x1` and `x2` are the predictor variables). State an interpretation of the interaction, in the context of the `Boston` dataset, in one or two sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789da998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a59e07e-6abb-4f6c-9c1b-760b11626ce7",
   "metadata": {},
   "source": [
    "### Question 3: Classification using KNN\n",
    "\n",
    "We'll now use the `Caravan` dataset from the `ISLP` package. (You may use `Caravan.describe()` to review details of the dataset.) In this dataset, the response variable of interest is `Purchase`, which indicates if a given customer purchased a caravan insurance policy. We will simultaneously use all other variables in the dataset to predict the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6449268e-0e33-4976-83cf-5ada4b29597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the \"Caravan\" dataset using the \"load_data\" function from the ISLP package\n",
    "Caravan = load_data('Caravan')\n",
    "\n",
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad60779b-cba9-4972-aeeb-b89e65fda11c",
   "metadata": {},
   "source": [
    "Before fitting any model, it is essential to understand our data. Answer the following questions about the `Caravan` dataset (Hint: use `print` and `describe`):  \n",
    "_(i)_ How many observations (rows) does the dataset contain?    \n",
    "_(ii)_ How many variables (columns) does the dataset contain?    \n",
    "_(iii)_ What 'variable' type is the response variable `Purchase` (e.g., 'character', 'factor', 'numeric', etc)? What are the 'levels' of the variable?    \n",
    "_(iv)_ How many predictor variables do we have (Hint: all variables other than `Purchase`)?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a8ec5-98e4-431d-967b-ae1482127de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d31d9",
   "metadata": {},
   "source": [
    "Next, we must preform 'pre-processing' or 'data munging', to prepare our data for classification/prediction. For KNN, there are three essential steps. A first essential step is to 'standardize' the predictor variables. We can achieve this using the `scaler` method, provided as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2901b1-82ce-4729-88d9-7d9985336221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select predictors (excluding the 86th column)\n",
    "predictors = Caravan.iloc[:, :-1]\n",
    "\n",
    "# Standardize the predictors\n",
    "scaler = StandardScaler()\n",
    "predictors_standardized = pd.DataFrame(scaler.fit_transform(predictors), columns=predictors.columns)\n",
    "\n",
    "# Display the head of the standardized predictors\n",
    "print(predictors_standardized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b3eaa-698e-4190-97cd-098e0e3d532e",
   "metadata": {},
   "source": [
    "_(v)_ Why is it important to standardize the predictor variables?  \n",
    "_(vi)_ Why did we elect not to standard our response variable `Purchase`?  \n",
    "\n",
    "_(vii)_ A second essential step is to set a random seed. Do so below (Hint: use the `random.seed` function). Why is setting a seed important? Is the particular seed value important? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230fd782-cfe1-45e6-ad00-a67e6b04d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4862c6-ed52-402f-b3f0-fead91646033",
   "metadata": {},
   "source": [
    "_(viii)_ A third essential step is to split our standardized data into separate training and testing sets. We will split into 75% training and 25% testing. The provided code randomly partitions our data, and creates linked training sets for the predictors and response variables. Extend the code to create a non-overlapping test set for the predictors and response variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9f219-571b-476b-9f5b-b47431c803b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random vector of True and False values\n",
    "split = np.random.choice([True, False], size=len(predictors_standardized), replace=True, p=[0.75, 0.25])\n",
    "\n",
    "# Define the training set for X (predictors)\n",
    "training_X = predictors_standardized[split]\n",
    "\n",
    "# Define the training set for Y (response)\n",
    "training_Y = Caravan.loc[split, 'Purchase']\n",
    "\n",
    "# Define the testing set for X (predictors)\n",
    "testing_X = predictors_standardized[~split]\n",
    "\n",
    "# Define the testing set for Y (response)\n",
    "testing_Y = Caravan.loc[~split, 'Purchase']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f16dbc-0be6-4cc8-b2c4-edab7042c702",
   "metadata": {},
   "source": [
    "_(ix)_ We are finally set to fit the KNN model. In Python, we can use the `KNeighborsClassifier()` function. Fit the KNN with k=1. (You may review arguments to knn by typing `help(knn.fit)`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a117de-279b-4320-b64e-4051ba2887d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33a32a-95d3-49db-bb1b-663360267b18",
   "metadata": {},
   "source": [
    "Using your fit model, answer the following questions:   \n",
    "_(x)_ What is the prediction accuracy? (Hint: use the `score` method, and compare your model to `testing_Y`)  \n",
    "_(xi)_ What is the predictor error ? (Hint: compute it from the accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbe6c4-1a4d-4f06-9e2e-597da03952ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction accuracy rate\n",
    "\n",
    "# prediction error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9342c-9dcd-4f6d-b437-6065417483db",
   "metadata": {},
   "source": [
    "_(xii)_ How does this prediction error/accuracy compare to what could be achieved via random guesses? To answer this, consider the percent of customers in the `Caravan` dataset who actually purchase insurance, computed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ade30-3465-4104-b300-61d78b319d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of customers who purchase insurance\n",
    "percentage_purchase = (Caravan['Purchase'].eq('Yes').sum() / len(Caravan['Purchase'])) * 100\n",
    "\n",
    "print(percentage_purchase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e19b5e-ad65-47f8-a3ef-e0f68a75048e",
   "metadata": {},
   "source": [
    "_(xiii)_ Fit a second KNN model, with $K=3$. Does this model perform better (i.e., have higher accuracy, compared to a random guess)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "497a84dc8fec8cf8d24e7e87b6d954c9a18a327edc66feb9b9ea7e9e72cc5c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
